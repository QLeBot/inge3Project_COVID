{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook from : https://www.kaggle.com/code/jiaowoguanren/sars-cov-2-ct-scan-dataset-classification-tf-0-99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "import pathlib, splitfolders\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import  ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE OF SARSCOV2-CTSCAN-DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 2481 files [00:01, 2033.41 files/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1736 images belonging to 2 classes.\n",
      "Found 371 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "img_height, img_width = 300, 300\n",
    "input_shape = (img_height, img_width, 3)\n",
    "\n",
    "def create_data_binary(data_bs):\n",
    "    data_bs = pathlib.Path(data_bs)\n",
    "    splitfolders.ratio(data_bs, output='../sarscov2-ctscan-dataset-splitted/', seed=1234, ratio=(0.7, 0.15, 0.15), group_prefix=None)\n",
    "    data_gen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "    train_ds = data_gen.flow_from_directory('../sarscov2-ctscan-dataset-splitted/train/', target_size=(img_height, img_width),\n",
    "                                            class_mode='binary', batch_size=batch_size, subset='training')\n",
    "    val_ds = data_gen.flow_from_directory('../sarscov2-ctscan-dataset-splitted/val/', target_size=(img_height, img_width),\n",
    "                                          class_mode='binary', batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_ds, val_ds\n",
    "\n",
    "\n",
    "train_data, val_data = create_data_binary('../sarscov2-ctscan-dataset/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE OF COVID-CT-master DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "img_height, img_width = 150, 150\n",
    "input_shape = (img_height, img_width, 3)\n",
    "\n",
    "data_gen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "\"\"\"\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                  zoom_range=0.2,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  fill_mode='nearest')\n",
    "\"\"\"\n",
    "                                  \n",
    "train_data = data_gen.flow_from_directory(\"../COVID-CT-master/Dataset/train/\",\n",
    "                                          target_size=(img_height, img_width),\n",
    "                                          batch_size = batch_size,\n",
    "                                          class_mode = 'binary',\n",
    "                                          subset='training')\n",
    "                                         \n",
    "test_data = data_gen.flow_from_directory(\"../COVID-CT-master/Dataset/test/\",\n",
    "                                          target_size=(img_height, img_width),\n",
    "                                          batch_size = batch_size,\n",
    "                                          class_mode = 'binary')\n",
    "\n",
    "val_data = data_gen.flow_from_directory(\"../COVID-CT-master/Dataset/val/\",\n",
    "                                          target_size=(img_height, img_width),\n",
    "                                          batch_size = batch_size,\n",
    "                                          class_mode = 'binary',\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "        self.C1 = Conv2D(32, (3 * 3), padding='same', input_shape = input_shape)\n",
    "        self.B1 = BatchNormalization()\n",
    "        self.A1 = Activation('relu')\n",
    "        self.P1 = MaxPooling2D(2, padding='same')\n",
    "        \n",
    "        self.C2 = Conv2D(32, (3 * 3), padding='same')\n",
    "        self.B2 = BatchNormalization()\n",
    "        self.A2 = Activation('relu')\n",
    "        self.P2 = MaxPooling2D(2, padding='same')\n",
    "        self.Dr1 = Dropout(0.3)\n",
    "        \n",
    "        self.C3 = Conv2D(32, (3 * 3), padding='same')\n",
    "        self.B3 = BatchNormalization()\n",
    "        self.A3 = Activation('relu')\n",
    "        self.P3 = MaxPooling2D(2, padding='same')\n",
    "        self.Dr2 = Dropout(0.3)\n",
    "        \n",
    "        self.F1 = Flatten()\n",
    "        self.D1 = Dense(256, activation='relu')\n",
    "        self.B4 = BatchNormalization()\n",
    "        self.D2 = Dense(256, activation='relu')\n",
    "        self.D3 = Dense(256, activation='relu')\n",
    "        self.D4 = Dense(256, activation='relu')\n",
    "        self.Dr3 = Dropout(0.3)\n",
    "        self.D5 = Dense(1, activation='sigmoid')\n",
    "        \n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.C1(x)\n",
    "        x = self.B1(x)\n",
    "        x = self.A1(x)\n",
    "        x = self.P1(x)\n",
    "        \n",
    "        x = self.C2(x)\n",
    "        x = self.B2(x)\n",
    "        x = self.A2(x)\n",
    "        x = self.P2(x)\n",
    "        x = self.Dr1(x)\n",
    "        \n",
    "        x = self.C3(x)\n",
    "        x = self.B3(x)\n",
    "        x = self.A3(x)\n",
    "        x = self.P3(x)\n",
    "        x = self.Dr2(x)\n",
    "        \n",
    "        x = self.F1(x)\n",
    "        x = self.D1(x)\n",
    "        x = self.B4(x)\n",
    "        x = self.D2(x)\n",
    "        x = self.D3(x)\n",
    "        x = self.D4(x)\n",
    "        x = self.Dr3(x)\n",
    "        y = self.D5(x)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def __repr__(self):\n",
    "        name = 'Huang_Model'\n",
    "        return name\n",
    "    \n",
    "    \n",
    "net = BaseModel()\n",
    "\n",
    "net.compile(optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "checkpoint_save_path = './Model.ckpt'\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    net.load_weights(checkpoint_save_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path, save_weights_only=True,\n",
    "                                                 save_best_only=True)\n",
    "\n",
    "#history = net.fit(train_data, epochs=30, batch_size=batch_size, callbacks=[cp_callback])\n",
    "history = net.fit(train_data, epochs=30, batch_size=batch_size)\n",
    "\n",
    "net.summary()\n",
    "\n",
    "file = open('./weights.txt', 'w')\n",
    "for v in net.trainable_variables:\n",
    "    file.write(str(v.name) + '\\n')\n",
    "    file.write(str(v.shape) + '\\n')\n",
    "    file.write(str(v.numpy()) + '\\n')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1736 files belonging to 2 classes.\n",
      "Using 1389 files for training.\n",
      "Found 374 files belonging to 2 classes.\n",
      "Using 74 files for validation.\n"
     ]
    }
   ],
   "source": [
    "disease_types = ['COVID', 'non-COVID']\n",
    "\n",
    "data_dir = '../sarscov2-ctscan-dataset-splitted/'\n",
    "\n",
    "# resize images from data_dir train, test and val and create new dataset resized\n",
    "def resize_images(data_dir):\n",
    "    # resize images from data_dir train, test and val and create new dataset resized\n",
    "    for folder in ['train', 'test', 'val']:\n",
    "        for file in os.listdir(os.path.join(data_dir, folder)):\n",
    "            if file.endswith('.jpg'):\n",
    "\n",
    "                img = cv2.imread(os.path.join(data_dir, folder, file))\n",
    "                img = cv2.resize(img, (224, 224))\n",
    "                cv2.imwrite(os.path.join(data_dir, 'resized', folder, file), img)\n",
    "\n",
    "# resize_images(data_dir)\n",
    "\n",
    "# create data generator for train, test and val\n",
    "def create_data_binary(data_dir):\n",
    "    data_dir = pathlib.Path(data_dir)\n",
    "    # create data generator for train, test and val\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        os.path.join(data_dir, 'train'),\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=123,\n",
    "        image_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        label_mode='binary')\n",
    "    test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        os.path.join(data_dir, 'test'),\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=123,\n",
    "        image_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        label_mode='binary')\n",
    "    return train_ds, test_ds\n",
    "\n",
    "train_ds, test_ds = create_data_binary('../sarscov2-ctscan-dataset-splitted/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(VGG16Model, self).__init__()\n",
    "        \n",
    "        self.C1 = Conv2D(32, (3 * 3), padding='same', input_shape = input_shape)\n",
    "\n",
    "        #self.VGG = VGG16(weights='imagenet', include_top = False, input_shape= input_shape)\n",
    "        self.VGG = VGG16(weights='imagenet', include_top = False)\n",
    "\n",
    "        self.GAP = GlobalAveragePooling2D()\n",
    "        self.B1 = BatchNormalization()\n",
    "\n",
    "        self.D1 = Dense(32, activation='relu')\n",
    "        self.B2 = BatchNormalization()\n",
    "        \n",
    "        self.D2 = Dense(32, activation='softmax')\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.C1(x)\n",
    "        x = self.VGG(x)\n",
    "        x = self.GAP(x)\n",
    "        x = self.B1(x)\n",
    "        x = self.D1(x)\n",
    "        x = self.B2(x)\n",
    "        y = self.D2(x)\n",
    "        \n",
    "        return y\n",
    "\n",
    "    def __repr__(self):\n",
    "        name = 'VGG16Model'\n",
    "        return name\n",
    "        \n",
    "net = VGG16Model()\n",
    "\n",
    "optimizer = Adam(learning_rate= 0.003, beta_1 = 0.9, beta_2 = 0.999, epsilon = 0.1, decay = 0.0)\n",
    "net.compile(loss = 'categorical_crossentropy', optimizer =optimizer, metrics = ['accuracy'])\n",
    "\n",
    "annealer = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.70, patience = 5, verbose = 1, min_lr = 1e-4)\n",
    "\n",
    "# Fits the model on batches with real-time data augmentation\n",
    "#history = net.fit(X_Train, epochs=epochs, batch_size = batch_size, callbacks = [annealer])\n",
    "history = net.fit(train_ds, epochs=epochs, batch_size = batch_size)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc)\n",
    "plt.title('Training Acc')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss)\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
