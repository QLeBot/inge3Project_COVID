{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook from : https://www.kaggle.com/code/jiaowoguanren/sars-cov-2-ct-scan-dataset-classification-tf-0-99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "import pathlib, splitfolders\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import  ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE OF SARSCOV2-CTSCAN-DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 2481 files [00:01, 1440.57 files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1736 images belonging to 2 classes.\n",
      "Found 371 images belonging to 2 classes.\n",
      "Found 374 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "img_height, img_width = 300, 300\n",
    "input_shape = (img_height, img_width, 3)\n",
    "\n",
    "def create_data_binary(data_bs):\n",
    "    data_bs = pathlib.Path(data_bs)\n",
    "    splitfolders.ratio(data_bs, output='../sarscov2-ctscan-dataset-splitted/', seed=1234, ratio=(0.7, 0.15, 0.15), group_prefix=None)\n",
    "    data_gen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "    train_ds = data_gen.flow_from_directory('../sarscov2-ctscan-dataset-splitted/train/', target_size=(img_height, img_width),\n",
    "                                            class_mode='binary', batch_size=batch_size, subset='training')\n",
    "    val_ds = data_gen.flow_from_directory('../sarscov2-ctscan-dataset-splitted/val/', target_size=(img_height, img_width),\n",
    "                                          class_mode='binary', batch_size=batch_size, shuffle=False)\n",
    "    test_ds = data_gen.flow_from_directory('../sarscov2-ctscan-dataset-splitted/test/', target_size=(img_height, img_width),\n",
    "                                          class_mode='binary', batch_size=batch_size, shuffle=False)\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "train_data, val_data, test_data = create_data_binary('../sarscov2-ctscan-dataset/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE OF COVID-CT-master DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "img_height, img_width = 150, 150\n",
    "input_shape = (img_height, img_width, 3)\n",
    "\n",
    "data_gen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "\"\"\"\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                  zoom_range=0.2,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  fill_mode='nearest')\n",
    "\"\"\"\n",
    "                                  \n",
    "train_data = data_gen.flow_from_directory(\"../COVID-CT-master/Dataset/train/\",\n",
    "                                          target_size=(img_height, img_width),\n",
    "                                          batch_size = batch_size,\n",
    "                                          class_mode = 'binary',\n",
    "                                          subset='training')\n",
    "                                         \n",
    "test_data = data_gen.flow_from_directory(\"../COVID-CT-master/Dataset/test/\",\n",
    "                                          target_size=(img_height, img_width),\n",
    "                                          batch_size = batch_size,\n",
    "                                          class_mode = 'binary')\n",
    "\n",
    "val_data = data_gen.flow_from_directory(\"../COVID-CT-master/Dataset/val/\",\n",
    "                                          target_size=(img_height, img_width),\n",
    "                                          batch_size = batch_size,\n",
    "                                          class_mode = 'binary',\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "        self.C1 = Conv2D(32, (3 * 3), padding='same', input_shape = input_shape)\n",
    "        self.B1 = BatchNormalization()\n",
    "        self.A1 = Activation('relu')\n",
    "        self.P1 = MaxPooling2D(2, padding='same')\n",
    "        \n",
    "        self.C2 = Conv2D(32, (3 * 3), padding='same')\n",
    "        self.B2 = BatchNormalization()\n",
    "        self.A2 = Activation('relu')\n",
    "        self.P2 = MaxPooling2D(2, padding='same')\n",
    "        self.Dr1 = Dropout(0.3)\n",
    "        \n",
    "        self.C3 = Conv2D(32, (3 * 3), padding='same')\n",
    "        self.B3 = BatchNormalization()\n",
    "        self.A3 = Activation('relu')\n",
    "        self.P3 = MaxPooling2D(2, padding='same')\n",
    "        self.Dr2 = Dropout(0.3)\n",
    "        \n",
    "        self.F1 = Flatten()\n",
    "        self.D1 = Dense(256, activation='relu')\n",
    "        self.B4 = BatchNormalization()\n",
    "        self.D2 = Dense(256, activation='relu')\n",
    "        self.D3 = Dense(256, activation='relu')\n",
    "        self.D4 = Dense(256, activation='relu')\n",
    "        self.Dr3 = Dropout(0.3)\n",
    "        self.D5 = Dense(1, activation='sigmoid')\n",
    "        \n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.C1(x)\n",
    "        x = self.B1(x)\n",
    "        x = self.A1(x)\n",
    "        x = self.P1(x)\n",
    "        \n",
    "        x = self.C2(x)\n",
    "        x = self.B2(x)\n",
    "        x = self.A2(x)\n",
    "        x = self.P2(x)\n",
    "        x = self.Dr1(x)\n",
    "        \n",
    "        x = self.C3(x)\n",
    "        x = self.B3(x)\n",
    "        x = self.A3(x)\n",
    "        x = self.P3(x)\n",
    "        x = self.Dr2(x)\n",
    "        \n",
    "        x = self.F1(x)\n",
    "        x = self.D1(x)\n",
    "        x = self.B4(x)\n",
    "        x = self.D2(x)\n",
    "        x = self.D3(x)\n",
    "        x = self.D4(x)\n",
    "        x = self.Dr3(x)\n",
    "        y = self.D5(x)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def __repr__(self):\n",
    "        name = 'Huang_Model'\n",
    "        return name\n",
    "    \n",
    "    \n",
    "net = BaseModel()\n",
    "\n",
    "net.compile(optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "checkpoint_save_path = './Model.ckpt'\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    net.load_weights(checkpoint_save_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path, save_weights_only=True,\n",
    "                                                 save_best_only=True)\n",
    "\n",
    "#history = net.fit(train_data, epochs=30, batch_size=batch_size, callbacks=[cp_callback])\n",
    "history = net.fit(train_data, epochs=30, batch_size=batch_size)\n",
    "\n",
    "net.summary()\n",
    "\n",
    "file = open('./weights.txt', 'w')\n",
    "for v in net.trainable_variables:\n",
    "    file.write(str(v.name) + '\\n')\n",
    "    file.write(str(v.shape) + '\\n')\n",
    "    file.write(str(v.numpy()) + '\\n')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 17:37:03.889082: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 45s 799ms/step - loss: 0.4550 - accuracy: 0.7892\n",
      "Epoch 2/30\n",
      "55/55 [==============================] - 44s 804ms/step - loss: 0.3420 - accuracy: 0.8543\n",
      "Epoch 3/30\n",
      "55/55 [==============================] - 49s 883ms/step - loss: 0.2633 - accuracy: 0.8923\n",
      "Epoch 4/30\n",
      "55/55 [==============================] - 47s 852ms/step - loss: 0.2377 - accuracy: 0.9003\n",
      "Epoch 5/30\n",
      "55/55 [==============================] - 48s 871ms/step - loss: 0.1945 - accuracy: 0.9263\n",
      "Epoch 6/30\n",
      "55/55 [==============================] - 49s 895ms/step - loss: 0.2564 - accuracy: 0.8934\n",
      "Epoch 7/30\n",
      "55/55 [==============================] - 54s 988ms/step - loss: 0.1578 - accuracy: 0.9355\n",
      "Epoch 8/30\n",
      "55/55 [==============================] - 52s 943ms/step - loss: 0.1400 - accuracy: 0.9482\n",
      "Epoch 9/30\n",
      "55/55 [==============================] - 52s 937ms/step - loss: 0.1147 - accuracy: 0.9585\n",
      "Epoch 10/30\n",
      "55/55 [==============================] - 60s 1s/step - loss: 0.0865 - accuracy: 0.9637\n",
      "Epoch 11/30\n",
      "55/55 [==============================] - 52s 947ms/step - loss: 0.0931 - accuracy: 0.9620\n",
      "Epoch 12/30\n",
      "55/55 [==============================] - 54s 983ms/step - loss: 0.0971 - accuracy: 0.9631\n",
      "Epoch 13/30\n",
      "55/55 [==============================] - 58s 1s/step - loss: 0.0685 - accuracy: 0.9770\n",
      "Epoch 14/30\n",
      "55/55 [==============================] - 54s 987ms/step - loss: 0.0637 - accuracy: 0.9775\n",
      "Epoch 15/30\n",
      "55/55 [==============================] - 59s 1s/step - loss: 0.0504 - accuracy: 0.9816\n",
      "Epoch 16/30\n",
      "55/55 [==============================] - 58s 1s/step - loss: 0.0718 - accuracy: 0.9752\n",
      "Epoch 17/30\n",
      "55/55 [==============================] - 59s 1s/step - loss: 0.0430 - accuracy: 0.9839\n",
      "Epoch 18/30\n",
      "55/55 [==============================] - 53s 967ms/step - loss: 0.0305 - accuracy: 0.9885\n",
      "Epoch 19/30\n",
      "55/55 [==============================] - 58s 1s/step - loss: 0.0574 - accuracy: 0.9804\n",
      "Epoch 20/30\n",
      "55/55 [==============================] - 53s 960ms/step - loss: 0.0559 - accuracy: 0.9844\n",
      "Epoch 21/30\n",
      "55/55 [==============================] - 54s 985ms/step - loss: 0.0483 - accuracy: 0.9844\n",
      "Epoch 22/30\n",
      "55/55 [==============================] - 53s 953ms/step - loss: 0.0416 - accuracy: 0.9850\n",
      "Epoch 23/30\n",
      "55/55 [==============================] - 51s 920ms/step - loss: 0.0749 - accuracy: 0.9775\n",
      "Epoch 24/30\n",
      "55/55 [==============================] - 53s 956ms/step - loss: 0.0454 - accuracy: 0.9868\n",
      "Epoch 25/30\n",
      "55/55 [==============================] - 53s 957ms/step - loss: 0.0436 - accuracy: 0.9827\n",
      "Epoch 26/30\n",
      "55/55 [==============================] - 51s 933ms/step - loss: 0.0489 - accuracy: 0.9839\n",
      "Epoch 27/30\n",
      "55/55 [==============================] - 51s 930ms/step - loss: 0.0176 - accuracy: 0.9925\n",
      "Epoch 28/30\n",
      "55/55 [==============================] - 53s 959ms/step - loss: 0.0051 - accuracy: 0.9994\n",
      "Epoch 29/30\n",
      "55/55 [==============================] - 52s 953ms/step - loss: 0.0092 - accuracy: 0.9977\n",
      "Epoch 30/30\n",
      "55/55 [==============================] - 54s 985ms/step - loss: 0.0559 - accuracy: 0.9821\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_26 (Conv2D)          (None, 300, 300, 32)      7808      \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 300, 300, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation (Activation)     (None, 300, 300, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 150, 150, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 150, 150, 32)      82976     \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 150, 150, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 150, 150, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 75, 75, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75, 75, 32)        0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 75, 75, 32)        82976     \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 75, 75, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 75, 75, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 38, 38, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 38, 38, 32)        0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 46208)             0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 256)               11829504  \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,202,305\n",
      "Trainable params: 12,201,601\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net = tf.keras.Sequential(\n",
    "    [\n",
    "        Conv2D(32, (3 * 3), padding='same', input_shape = input_shape),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(2, padding='same'),\n",
    "\n",
    "        Conv2D(32, (3 * 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(2, padding='same'),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Conv2D(32, (3 * 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(2, padding='same'),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "net.compile(optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# Define the callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(filepath='model_checkpoint.h5', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "history = net.fit(train_data, epochs=epochs, batch_size=batch_size)\n",
    "history = net.fit(train_data, epochs=epochs, validation_data=val_data, callbacks=[early_stop, checkpoint])\n",
    "\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 18:13:55.437456: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 3s 225ms/step - loss: 0.8805 - accuracy: 0.7353\n",
      "Test loss: 0.880\n",
      "Test accuracy: 0.735\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = net.evaluate(test_data)\n",
    "print(\"Test loss: %.3f\" % test_loss)\n",
    "print(\"Test accuracy: %.3f\" % test_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VGG16 model with pre-trained weights\n",
    "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Freeze the pre-trained layers in the model\n",
    "for layer in vgg16_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add a new classifier on top of the pre-trained model\n",
    "model = tf.keras.Sequential([\n",
    "    vgg16_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with binary crossentropy loss and Adam optimizer\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define the callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(filepath='model_checkpoint.h5', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Train the model with the training data and validate on the validation data\n",
    "history = model.fit(train_data, epochs=10, validation_data=val_data)\n",
    "#history = model.fit(train_data, epochs=epochs, validation_data=val_data, callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and Loss graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc)\n",
    "plt.title('Training Acc')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss)\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data)\n",
    "print(\"Test loss: %.3f\" % test_loss)\n",
    "print(\"Test accuracy: %.3f\" % test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
