{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\"COVID-CT-master/Dataset/train/\",\n",
    "                                          target_size=(150,150),\n",
    "                                          batch_size = 32,\n",
    "                                          class_mode = 'binary')\n",
    "                                         \n",
    "test_generator = test_datagen.flow_from_directory(\"COVID-CT-master/Dataset/test/\",\n",
    "                                          target_size=(150,150),\n",
    "                                          batch_size =32,\n",
    "                                          class_mode = 'binary')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\"COVID-CT-master/Dataset/val/\",\n",
    "                                          target_size=(150,150),\n",
    "                                          batch_size =32,\n",
    "                                          class_mode = 'binary')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract X_train, y_train, X_test, y_test for a part of the data. NO LOOP OVER GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the X_train and y_train arrays from the training generator\n",
    "X_train, y_train = next(train_generator)\n",
    "\n",
    "# Extract the X_test and y_test arrays from the testing generator\n",
    "X_test, y_test = next(test_generator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract X_train, y_train, X_test, y_test for a part of the data. LOOP OVER GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of samples in the training and testing generators\n",
    "train_samples = len(train_generator.filenames)\n",
    "test_samples = len(test_generator.filenames)\n",
    "\n",
    "# Calculate the number of batches for the training and testing data\n",
    "train_batches = train_samples // 32 + (1 if train_samples % 32 else 0)\n",
    "test_batches = test_samples // 32 + (1 if test_samples % 32 else 0)\n",
    "\n",
    "# Create empty arrays to store the training and testing data\n",
    "X_train = np.zeros((train_samples, 150, 150, 3))\n",
    "y_train = np.zeros((train_samples,))\n",
    "X_test = np.zeros((test_samples, 150, 150, 3))\n",
    "y_test = np.zeros((test_samples,))\n",
    "\n",
    "# Fill the arrays with the training and testing data\n",
    "for i, (x, y) in enumerate(train_generator):\n",
    "    start = i * 32\n",
    "    end = min(start + 32, train_samples)\n",
    "    X_train[start:end] = x[:end-start]\n",
    "    y_train[start:end] = y[:end-start]\n",
    "    if end == train_samples:\n",
    "        break\n",
    "\n",
    "for i, (x, y) in enumerate(test_generator):\n",
    "    start = i * 32\n",
    "    end = min(start + 32, test_samples)\n",
    "    X_test[start:end] = x[:end-start]\n",
    "    y_test[start:end] = y[:end-start]\n",
    "    if end == test_samples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = tf.image.resize(image, (150, 150))\n",
    "    image = (image - 127.5) / 127.5\n",
    "    return image\n",
    "\n",
    "def create_first_cnn():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def create_second_cnn():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "def create_cascading_cnn_pipeline(first_cnn, second_cnn):\n",
    "    input_image = keras.Input(shape=(150, 150, 3))\n",
    "    processed_image = keras.layers.Lambda(preprocess_image)(input_image)\n",
    "    first_cnn_output = first_cnn(processed_image)\n",
    "    second_cnn_input = keras.layers.multiply([processed_image, first_cnn_output])\n",
    "    second_cnn_output = second_cnn(second_cnn_input)\n",
    "    return keras.Model(inputs=input_image, outputs=second_cnn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cnn = create_first_cnn()\n",
    "second_cnn = create_second_cnn()\n",
    "cascading_cnn = create_cascading_cnn_pipeline(first_cnn, second_cnn)\n",
    "# compile cascading cnn\n",
    "cascading_cnn.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "# fit cascading cnn\n",
    "#cascading_cnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "cascading_cnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=val_generator)\n",
    "\n",
    "# evaluate cascading cnn\n",
    "cascading_cnn.evaluate(X_test, y_test)\n",
    "\n",
    "# predict on test data\n",
    "y_pred = cascading_cnn.predict(X_test)\n",
    "\n",
    "# convert predictions classes to one hot vectors\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# plot the confusion matrix\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01, cmap=\"Greens\", linecolor=\"gray\", fmt= '.1f', ax=ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities for test set\n",
    "yhat_probs = cascading_cnn.predict(X_test, verbose=0)\n",
    "# predict crisp classes for test set\n",
    "yhat_classes = cascading_cnn.predict_classes(X_test, verbose=0)\n",
    "\n",
    "# reduce to 1d array\n",
    "yhat_probs = yhat_probs[:, 0]\n",
    "yhat_classes = yhat_classes[:, 0]\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, yhat_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, yhat_classes)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, yhat_classes)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, yhat_classes)\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "# kappa\n",
    "kappa = cohen_kappa_score(y_test, yhat_classes)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, yhat_probs)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test, yhat_classes)\n",
    "print(matrix)\n",
    "\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(y_test, yhat_probs)\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.', label='Cascading CNN')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "# calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, yhat_probs)\n",
    "# plot the precision-recall curve for the model\n",
    "plt.plot(recall, precision, marker='.', label='Cascading CNN')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
