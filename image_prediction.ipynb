{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 16:00:27.752146: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-20 16:00:27.752655: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import base model\n",
    "model_base = load_model('models/model_base.h5')\n",
    "# import VGG model\n",
    "model_vgg = load_model('models/model_vgg.h5')\n",
    "# import cascading model\n",
    "model_cascade = load_model('models/model_cascade.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictImage(filename):\n",
    "    img1 = image.load_img(filename)\n",
    "    \n",
    "    plt.imshow(img1)\n",
    " \n",
    "    Y = image.img_to_array(img1)\n",
    "    \n",
    "    X = np.expand_dims(Y,axis=0)\n",
    "    val = model_base.predict(X)\n",
    "    print(val)\n",
    "    if val == 1:\n",
    "        \n",
    "        plt.xlabel(\"NonCovid\",fontsize=30)\n",
    "        \n",
    "    \n",
    "    elif val == 0:\n",
    "        \n",
    "        plt.xlabel(\"Covid\",fontsize=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictImage(\"COVID-CT-master/Dataset/test/NonCOVID/0.jpg\")\n",
    "predictImage(\"COVID-CT-master/Dataset/test/COVID/2020.03.12.20034686-p17-91-1.png\")\n",
    "predictImage(\"COVID-CT-master/Dataset/test/NonCOVID/4%3.jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For sarscov2-ctscan-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[1.]]\n",
      "[0]\n",
      "Predicted class: COVID\n",
      "Image name: sarscov2-ctscan-dataset/non-COVID/Non-Covid (949).png\n",
      "Image folder: sarscov2-ctscan-dataset/non-COVID\n"
     ]
    }
   ],
   "source": [
    "# define the path to your dataset\n",
    "dataset_path = 'sarscov2-ctscan-dataset'\n",
    "\n",
    "# define the labels for your classes\n",
    "#class_labels = ['COVID', 'non-COVID']\n",
    "class_labels = {'COVID': 0, 'NonCOVID': 1}\n",
    "\n",
    "# create a list to hold all the images\n",
    "full_dataset = []\n",
    "# get all files in dataset_path\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        full_dataset.append(os.path.join(root, file))\n",
    "\n",
    "# select random image from full_dataset\n",
    "random_image = np.random.choice(full_dataset)\n",
    "\n",
    "# get the class_labels the random image is from\n",
    "folder = os.path.dirname(random_image)\n",
    "\n",
    "# load the image\n",
    "img = cv2.imread(random_image)\n",
    "# resize the image to match the input size of your model\n",
    "img = cv2.resize(img, (300, 300))\n",
    "# convert the image to a numpy array\n",
    "img = np.array(img)\n",
    "# add a dimension to the image to match the input size of your model\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "# make a prediction for the image\n",
    "prediction = model_vgg.predict(img)\n",
    "#prediction = np.squeeze(model_vgg.predict(img))\n",
    "print(prediction)\n",
    "\n",
    "# get class from prediction\n",
    "class_index = np.argmax(prediction, axis=1)\n",
    "print(class_index)\n",
    "\n",
    "# get the predicted class\n",
    "predicted_class = list(class_labels.keys())[list(class_labels.values()).index(class_index[0])]\n",
    "\n",
    "# print the predicted class\n",
    "print(\"Predicted class: {}\".format(predicted_class))\n",
    "\n",
    "# print image name\n",
    "print(\"Image name: {}\".format(random_image))\n",
    "\n",
    "# print image folder\n",
    "print(\"Image folder: {}\".format(folder))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For COVID-CT-master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Predicted class: CT_COVID\n",
      "Image name: COVID-CT-master/Images-processed/CT_NonCOVID/383.png\n",
      "Image folder: COVID-CT-master/Images-processed/CT_NonCOVID\n"
     ]
    }
   ],
   "source": [
    "# define the path to your dataset\n",
    "dataset_path = 'COVID-CT-master/Images-processed/'\n",
    "\n",
    "# define the labels for your classes\n",
    "class_labels = ['CT_COVID', 'CT_NonCOVID']\n",
    "\n",
    "# create a list to hold all the images\n",
    "full_dataset = []\n",
    "# get all files in dataset_path\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        full_dataset.append(os.path.join(root, file))\n",
    "\n",
    "# select random image from full_dataset\n",
    "random_image = np.random.choice(full_dataset)\n",
    "\n",
    "# get the class_labels the random image is from\n",
    "folder = os.path.dirname(random_image)\n",
    "\n",
    "# load the image\n",
    "img = cv2.imread(random_image)\n",
    "# resize the image to match the input size of your model\n",
    "img = cv2.resize(img, (300, 300))\n",
    "# convert the image to a numpy array\n",
    "img = np.array(img)\n",
    "# add a dimension to the image to match the input size of your model\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "# make a prediction for the image\n",
    "prediction = model_vgg.predict(img)\n",
    "\n",
    "# get the predicted class\n",
    "predicted_class = class_labels[np.argmax(prediction)]\n",
    "\n",
    "# print the predicted class\n",
    "print(\"Predicted class: {}\".format(predicted_class))\n",
    "\n",
    "# print image name\n",
    "print(\"Image name: {}\".format(random_image))\n",
    "\n",
    "# print the folder\n",
    "print(\"Image folder: {}\".format(folder))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
